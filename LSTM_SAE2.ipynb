{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load\n",
    "def Data_Load():\n",
    "    global df\n",
    "    df = pd.read_csv('D:/Denoising/Autoencoder/LSTM_SAE/Samsung.txt', sep = ',')\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(df[['CLOSE']])\n",
    "    df[\"Close\"] = scaled\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Slice_Window(size):\n",
    "    global window_list, x_train, x_test, y_train, y_test\n",
    "    window_list = np.zeros((len(df)-size+1,size,1))\n",
    "    count = 0\n",
    "    for i in range(len(df)-size+1):\n",
    "        end_idx = i+size\n",
    "        dff = df[i:end_idx]\n",
    "        dff.reset_index(inplace = True)\n",
    "        if len(dff)>=size:\n",
    "            for j in range(size):\n",
    "                window_list[count][j][0] = dff[\"Close\"][j]            \n",
    "            count += 1\n",
    "    \n",
    "    # Split Train and Test Set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(window_list, window_list, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Model():\n",
    "    global model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    timestamp = window_list.shape[1]\n",
    "    features = window_list.shape[2]\n",
    "\n",
    "    # Encoder LSTM cell1\n",
    "    model.add(keras.layers.LSTM(units=20, input_shape=(timestamp, features), return_sequences = True))\n",
    "    model.add(keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "    # Encoder LSTM cell2\n",
    "    model.add(keras.layers.LSTM(units=15, return_sequences=True))\n",
    "    model.add(keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "    # Encoder LSTM cell3\n",
    "    model.add(keras.layers.LSTM(units=10, return_sequences=False))\n",
    "    model.add(keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "    model.add(keras.layers.RepeatVector(timestamp))\n",
    "\n",
    "    # Decoder LSTM cell1\n",
    "    model.add(keras.layers.LSTM(units=10, return_sequences=True))\n",
    "    model.add(keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "    # Decoder LSTM cell2\n",
    "    model.add(keras.layers.LSTM(units=15, return_sequences=True))\n",
    "    model.add(keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "    # Decoder LSTM cell3\n",
    "    model.add(keras.layers.LSTM(units=20, return_sequences=True))\n",
    "    model.add(keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "    model.add(keras.layers.TimeDistributed(keras.layers.Dense(features)))\n",
    "    model.compile(loss='mse', optimizer = Adam(learning_rate = 0.0001))\n",
    "\n",
    "    return model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Output():\n",
    "    global mean_list, mean_list2\n",
    "    # Sum all window size units\n",
    "    mean_list = [0 for i in range(len(df))]\n",
    "    for i in range(len(window_list)):\n",
    "        for j in range(20):\n",
    "            mean_list[i+j] += pred[i][j]\n",
    "\n",
    "    # Calculate average\n",
    "    mean_list2= []\n",
    "    count = 19\n",
    "    for i in range(len(mean_list)):\n",
    "        if i < 20:\n",
    "            mean_list2.append(mean_list[i] / (i+1))\n",
    "        elif i >=20 and (i <= len(mean_list)-20):\n",
    "            mean_list2.append(mean_list[i] / 20)\n",
    "        else:\n",
    "            mean_list2.append(mean_list[i] / count)\n",
    "            count -= 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Output MAE\n",
    "def Check_MAE(idx):\n",
    "    global total_mae, total_mae2\n",
    "    total_mae = 0\n",
    "    total_mae2 = 0\n",
    "    stock_price = list(df[\"Close\"])\n",
    "    for i in range(len(window_list)):\n",
    "        mae = np.abs(stock_price[i] - window_list[idx][i])\n",
    "        total_mae += mae\n",
    "    total_mae2 = total_mae / len(window_list[idx])*100\n",
    "    return total_mae2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "616f588775ebd5684723f0fc88bdf016eafcafb45847b72d0199a5bd69bf316d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
